# -*- coding: utf-8 -*-
"""custom ml models in scit learn.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gZ_5HkQRmZgRwJBlscg2z42eKKHQUrxr
"""

import numpy as np
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.base import BaseEstimator, ClassifierMixin

data = load_iris()
X, y = data.data, data.target
xtrain, xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2, random_state=42)

class NearestCentroidClassifier(BaseEstimator , ClassifierMixin):
  def __init__(self):
    self.centroids_ = None
    self.classes_ = None

  def fit(self ,X,y):
    self.classes_ = np.unique(y)
    self.centroids_ = np.zeros((len(self.classes_) , X.shape[1])) # creates an numpy arrays of zeros with shape as (rows = classes , columns = features)

    for idx , cls in enumerate(self.classes_):
      self.centroids_[idx,:] = X[y==cls].mean(axis=0) # selects all data points from X that belong to the current class cls and assigns it to coressponding row(idx)

    return self

  def predict(self,X):
    distances = np.zeros((X.shape[0] , len(self.classes_)))

    for idx , centroid in enumerate(self.centroids_):
      # This is the core of the prediction. It calculates the Euclidean distance between each data point in X and the current centroid.
      distances[:,idx ] = np.linalg.norm(X-centroid , axis=1) #calculates the euclidian distance row wise and assigns the calculated distance to the corresponding columns

    return self.classes_[np.argmin(distances , axis=1)] # returns the prediction based on smallest distance

  def predict_proba(self,X):
    distances = np.zeros((X.shape[0] , len(self.classes_)))

    for idx , centroid in enumerate(self.centroids_):
      distances[:,idx] = np.linalg.norm(X-centroid , axis=1)

    inv_distances = 1/distances
    inv_dis_sum = np.sum(inv_distances , axis=1, keepdims=True)

    return inv_distances/inv_dis_sum

clf = NearestCentroidClassifier()
clf.fit(xtrain,ytrain)
clf.predict(xtest)
clf.predict_proba(xtest)

print(f"accuracy score --> {clf.score(xtest,ytest)*100} %")



class KNNClassifier_by_me(BaseEstimator, ClassifierMixin):
    def __init__(self, k=3):
        self.k = k

    def fit(self, X, y):
        self.X_train = np.array(X)
        self.y_train = np.array(y)
        return self  # Return self for method chaining

    def predict(self, X):
        X = np.array(X)
        return np.array([self._predict(x) for x in X])

    def _predict(self, x):
        distances = np.linalg.norm(self.X_train - x, axis=1)  # Vectorized distance calculation
        k_indices = np.argsort(distances)[:self.k]
        k_nearest_labels = self.y_train[k_indices]
        most_common = np.bincount(k_nearest_labels).argmax()
        return most_common

    def score(self, X, y):
        y_pred = self.predict(X)
        return np.mean(y_pred == y)

    def predict_proba(self,X):
      X = np.array(X)
      probabilities = []

      for x in X:
        distances = np.linalg.norm(self.X_train - x, axis=1)
        k_indices = np.argsort(distances)[:self.k]
        k_nearest_labels = self.y_train[k_indices]
        most_common = np.bincount(k_nearest_labels).argmax()
        probabilities.append(most_common / self.k)

      return np.array(probabilities)


# Train KNN model
knn = KNNClassifier_by_me(k=5)
knn.fit(xtrain, ytrain)
y_pred = knn.predict(xtest)
pred_prob = knn.predict_proba(xtest)

# Evaluate model
accuracy = knn.score(xtest, ytest)
print(f'KNN Model Accuracy: {accuracy * 100:.2f}%')
print(f'Predicted probabilities for first test sample: {pred_prob[0]}')

